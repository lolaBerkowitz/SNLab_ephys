{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "\n",
    "# import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "from neuro_py.io import loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata for cheeseboard task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(r'Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\metadata.csv')\n",
    "basepaths = meta_df.basepath.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing inconsistencies in napari saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace 'learning' and 'probe' as videoname for napari output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for basepath in basepaths:\n",
    "    learning_csv = glob.glob(os.path.join(basepath, 'learning_*.csv'))\n",
    "    probe_csv = glob.glob(os.path.join(basepath, 'probe_*.csv'))\n",
    "\n",
    "    videos = glob.glob(os.path.join(basepath, '*.avi'))\n",
    "\n",
    "    for vidpath in videos:\n",
    "        vidname = os.path.basename(vidpath).strip('.avi')\n",
    "        if 'learn' in vidname:\n",
    "            # replace all csv names as vidname_*.csv\n",
    "            new_csv_name = [os.path.basename(vid).replace('learning', vidname) for vid in learning_csv]\n",
    "            [os.rename(old, os.path.join(basepath, new)) for old, new in zip(learning_csv, new_csv_name)]\n",
    "\n",
    "        elif 'probe' in vidname:\n",
    "            new_csv_name = [os.path.basename(vid).replace('probe', vidname) for vid in probe_csv]\n",
    "            [os.rename(old, os.path.join(basepath, new)) for old, new in zip(probe_csv, new_csv_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For basepath, find subfolders and rename .csv files within subfolders as subfolder_*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for basepath in basepaths:\n",
    "    # get all subfolders in basepath\n",
    "    subfolders = [f.path for f in os.scandir(basepath) if f.is_dir()]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        csvs = glob.glob(os.path.join(folder, '*.csv'))\n",
    "        for csv in csvs:\n",
    "            # check that basename of folder is not in csv name\n",
    "            if os.path.basename(folder) in os.path.basename(csv):\n",
    "                continue\n",
    "            # rename csv to foldername_csvname.csv and move to basepath\n",
    "            new_name = os.path.join(basepath, os.path.basename(folder) + '_' + os.path.basename(csv))\n",
    "            os.rename(csv, new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovering files...\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_probe-08192025134039-0000.avi\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_learn-08192025110030-0000.avi\n",
      "Initial file count: 2\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\data\\\\cohort_2\\\\4447\\\\4447_exposure1_phase3\\\\4447_newports_day1_probe-08192025134039-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\data\\\\cohort_2\\\\4447\\\\4447_exposure1_phase3\\\\4447_newports_day1_learn-08192025110030-0000.avi']\n",
      "filter to just probe sessions to start\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\data\\\\cohort_2\\\\4447\\\\4447_exposure1_phase3\\\\4447_newports_day1_probe-08192025134039-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\data\\\\cohort_2\\\\4447\\\\4447_exposure1_phase3\\\\4447_newports_day1_learn-08192025110030-0000.avi']\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_probe-08192025134039-0000.avi --- 0 of 2 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_probe-08192025134039-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_learn-08192025110030-0000.avi --- 1 of 2 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\\4447_newports_day1_learn-08192025110030-0000.avi --- not annotated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Goes through all the layers of the video, extracting the coordinates,\n",
    "# frames, and the visible data and creates a DataFrame with the according\n",
    "# coordinates for each frame.\n",
    "#\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    #A layer is a level at which an aspect of the video can be manipulated (i.e.,\n",
    "    #can contain videos, audio, images, text, or effects). Layers are used to\n",
    "    #superimpose on video clip over another or to add special efects.\n",
    "    for layer in point_layers:\n",
    "        # Extract point coordinates (N, 2)\n",
    "        points = layer.data\n",
    "        # Loads the frame data and, if not found, replaces with 0s\n",
    "        frames = layer.metadata.get(\"frames\", np.zeros(len(points), dtype=int))\n",
    "        # Loads the visible data and, if not found, replaces with 1s (always True)\n",
    "        visible = layer.metadata.get(\"visible\", np.ones(len(points), dtype=bool))\n",
    "\n",
    "        if len(points) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "\n",
    "        # Create DataFrame with required columns\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"index\": np.arange(len(points)),  # Index of each point\n",
    "                \"axis-0\": frames,  # Frame number\n",
    "                \"axis-1\": points[:, 0],  # X-coordinates -> first column of array\n",
    "                \"axis-2\": points[:, 1],  # Y-coordinates -> second column of array\n",
    "            }\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "#\n",
    "def update_point_visibility(layer, viewer):\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        return\n",
    "\n",
    "    # Gets the current frame from the video, starting from where the viewer is\n",
    "    current_frame = viewer.dims.current_step[0]\n",
    "    # Gets the metadata associated with frames\n",
    "    frames = layer.metadata[\"frames\"]\n",
    "\n",
    "    # Update visibility based on current -> so visibility is true for the frames\n",
    "    # before and at the frame the viewer is on\n",
    "    visible = frames <= current_frame\n",
    "    layer.metadata[\"visible\"] = visible\n",
    "\n",
    "    # Update the displayed points -> points that are displayed are the ones\n",
    "    # that are listed as visible\n",
    "    if len(layer.data) > 0:\n",
    "        layer.shown = visible\n",
    "\n",
    "\n",
    "def store_frame_metadata(layer, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "    num_points = len(layer.data)  # Total points in the layer\n",
    "\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        layer.metadata[\"frames\"] = np.zeros(num_points, dtype=int)  # Initialize\n",
    "        layer.metadata[\"visible\"] = np.ones(\n",
    "            num_points, dtype=bool\n",
    "        )  # Initialize visibility\n",
    "\n",
    "    existing_frames = layer.metadata[\"frames\"]  # Get stored frame numbers\n",
    "\n",
    "    # If new points were added, store their frame numbers\n",
    "    if num_points > len(existing_frames):\n",
    "        new_frames = np.full(\n",
    "            num_points - len(existing_frames), current_frame\n",
    "        )  # Assign current frame to new points\n",
    "        layer.metadata[\"frames\"] = np.concatenate(\n",
    "            [existing_frames, new_frames]\n",
    "        )  # Update frames\n",
    "        # New points should be visible if current frame >= their frame\n",
    "        new_visible = np.ones(num_points - len(existing_frames), dtype=bool)\n",
    "        layer.metadata[\"visible\"] = np.concatenate(\n",
    "            [layer.metadata[\"visible\"], new_visible]\n",
    "        )\n",
    "\n",
    "    # Update visibility for all points\n",
    "    update_point_visibility(layer, viewer)\n",
    "\n",
    "\n",
    "# Goes through each layer and modifies data based on certain events, saving the\n",
    "# data to the layer when press 'S' key\n",
    "def annotate_video(video_path):\n",
    "    vr = VideoReaderNP(video_path)\n",
    "    viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "    # Add point layers\n",
    "    rewards_layer = viewer.add_points(name=\"rewards\", face_color=\"red\", size=10)\n",
    "    start_layer = viewer.add_points(name=\"start\", face_color=\"green\", size=10)\n",
    "    trials_layer = viewer.add_points(name=\"trials\", face_color=\"blue\", size=10)\n",
    "\n",
    "    point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "    # Attach event listeners -> so whenever the data changes (i.e., points\n",
    "    # are removed, added, or modified) or the viewer changes a frame,\n",
    "    # updates metadata and changes visuals (i.e., visible points), respectively\n",
    "    for layer in point_layers:\n",
    "        # Update frame metadata when points are added\n",
    "        layer.events.data.connect(\n",
    "            lambda event, l=layer: store_frame_metadata(l, viewer)\n",
    "        )\n",
    "\n",
    "        # Update visibility when frame changes\n",
    "        viewer.dims.events.current_step.connect(\n",
    "            lambda event: update_point_visibility(layer, viewer)\n",
    "        )\n",
    "\n",
    "    # Bind save function to 'S' key\n",
    "    @viewer.bind_key(\"Shift-S\")\n",
    "    def save_on_keypress(viewer):\n",
    "        save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "# Checks trial durations, number of trials, number of rewards, and each trial\n",
    "# has only 1 start time\n",
    "def verify_manual_annotation(video_path, fs=40, trial_wiggle_room=10):\n",
    "    if not is_annotated(video_path):\n",
    "        print(f\"{video_path} --- not annotated\")\n",
    "        return\n",
    "\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    trials = pd.read_csv(os.path.join(video_dir, \"trials.csv\"))\n",
    "    rewards = pd.read_csv(os.path.join(video_dir, \"rewards.csv\"))\n",
    "    start = pd.read_csv(os.path.join(video_dir, \"start.csv\"))\n",
    "\n",
    "    # check if any trial durations\n",
    "    trials = trials.sort_values(\"axis-0\").reset_index(drop=True)\n",
    "    # fills the even indexes of trials with start times\n",
    "    start_ind = trials[trials.index % 2 == 0][\"axis-0\"]\n",
    "    # fills the odd indexes of trials with end times\n",
    "    stop_ind = trials[trials.index % 2 == 1][\"axis-0\"]\n",
    "    # converts the indices into seconds by dividing by sampling frequency\n",
    "    starts = start_ind / fs\n",
    "    stops = stop_ind / fs\n",
    "    # check if same number of starts and stops -> sanity check ig?\n",
    "    assert len(starts) == len(stops), (\n",
    "        f\"Found {len(starts)} starts and {len(stops)} stops\"\n",
    "    )\n",
    "    # get durations per trial\n",
    "    durations = stops.values - starts.values\n",
    "\n",
    "    # check if any trial is longer than 360 seconds\n",
    "    assert durations.max() < 60 * 6, f\"Found {durations.max()} seconds\"\n",
    "    if durations.max() > 90:\n",
    "        print(f\"{video_path} --- Found {durations.max()} seconds\")\n",
    "\n",
    "    # check if any trial is shorter than 90 seconds\n",
    "    if durations.min() < 90:\n",
    "        test = 1\n",
    "    assert durations.min() > 5, f\"Found {durations.min()} seconds\"\n",
    "\n",
    "    # check if more than 25 trials\n",
    "    assert durations.shape[0] <= 30, f\"Found {durations.shape[0]} trials\"\n",
    "\n",
    "    # check if at least 2 rewards\n",
    "    assert rewards.shape[0] >= 2, f\"Found {rewards.shape[0]} rewards\"\n",
    "\n",
    "    # check if 1 start\n",
    "    assert start.shape[0] == 1, f\"Found {start.shape[0]} start points\"\n",
    "\n",
    "    print(f\"{video_path} --- verified\")\n",
    "\n",
    "\n",
    "def is_annotated(video_path):\n",
    "    video_dir = Path(video_path).parent\n",
    "    print(\"hey\")\n",
    "    if os.path.exists(os.path.join(video_dir, \"rewards.csv\")) & os.path.exists(os.path.join(video_dir, \"start.csv\")) & os.path.exists(os.path.join(video_dir, \"trials.csv\")):\n",
    "        print(\"treldkjf\")\n",
    "    else:\n",
    "        print(\"suckjerja;ldkjf;alskjdfa;lsdkjf\")\n",
    "    return (\n",
    "        os.path.exists(os.path.join(video_dir, \"rewards.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"start.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"trials.csv\"))\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"discovering files...\")\n",
    "\n",
    "    # files = glob.glob(r\"U:\\data\\hpc_ctx_project\\**\\*.avi\", recursive=True)\n",
    "\n",
    "    # files_series = pd.Series(files)\n",
    "    # idx = (\n",
    "    #     files_series.str.contains(\"cheeseboard|cheesboard|open_field|acquisition|probe\")\n",
    "    #     & ~files_series.str.contains(\"backup\")\n",
    "    #     & ~files_series.str.contains(\"test\")\n",
    "    # )\n",
    "\n",
    "    # files = list(compress(files, idx))\n",
    "    #basepaths = pd.read_csv(r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\sample_data.csv\").basepath.unique()\n",
    "    #files = []\n",
    "\n",
    "    #for folder in basepaths:\n",
    "     #   print('hei')\n",
    "      #  files.extend(glob.glob(os.path.join(folder, \"**\", \"*.avi\"), recursive=True))\n",
    "\n",
    "      # 🔧 Hardcode your base folder here\n",
    "    base_folder = r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\data\\cohort_2\\4447\\4447_exposure1_phase3\"\n",
    "# Recursively search for .avi files in all subfolders\n",
    "    files = glob.glob(os.path.join(base_folder, \"**\", \"*.avi\"), recursive=True)\n",
    "\n",
    "# Print all found .avi files\n",
    "    for f in files:\n",
    "        print(f)\n",
    "\n",
    "    print(f\"Initial file count: {len(files)}\")\n",
    "    print(files)\n",
    "\n",
    "    print(\"filter to just probe sessions to start\")\n",
    "    files_series = pd.Series(files)\n",
    "    idx = ~files_series.str.contains(\"backup\") & ~files_series.str.contains(\"test\")\n",
    "    files = list(compress(files, idx))\n",
    "    print(files)\n",
    "    for video_path_i, video_path in enumerate(files):\n",
    "        print(f\"{video_path} --- {video_path_i} of {len(files)} files\")\n",
    "\n",
    "        video_dir = Path(video_path).parent\n",
    "\n",
    "        if is_annotated(video_path):\n",
    "            verify_manual_annotation(video_path)\n",
    "            continue\n",
    "\n",
    "        annotate_video(video_path)\n",
    "        verify_manual_annotation(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovering files...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\sample_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 211\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscovering files...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# files = glob.glob(r\"U:\\data\\hpc_ctx_project\\**\\*.avi\", recursive=True)\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# files_series = pd.Series(files)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# files = list(compress(files, idx))\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m basepaths \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mY:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlaura_berkowitz\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbehavior_validation\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mappps1_cheeseboard\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdlc_videos\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msample_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbasepath\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m    212\u001b[0m files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m basepaths:\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\sample_data.csv'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "\n",
    "# Goes through all the layers of the video, extracting the coordinates,\n",
    "# frames, and the visible data and creates a DataFrame with the according\n",
    "# coordinates for each frame.\n",
    "#\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    #A layer is a level at which an aspect of the video can be manipulated (i.e.,\n",
    "    #can contain videos, audio, images, text, or effects). Layers are used to\n",
    "    #superimpose on video clip over another or to add special efects.\n",
    "    for layer in point_layers:\n",
    "        # Extract point coordinates (N, 2)\n",
    "        points = layer.data\n",
    "        # Loads the frame data and, if not found, replaces with 0s\n",
    "        frames = layer.metadata.get(\"frames\", np.zeros(len(points), dtype=int))\n",
    "        # Loads the visible data and, if not found, replaces with 1s (always True)\n",
    "        visible = layer.metadata.get(\"visible\", np.ones(len(points), dtype=bool))\n",
    "\n",
    "        if len(points) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "\n",
    "        # Create DataFrame with required columns\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"index\": np.arange(len(points)),  # Index of each point\n",
    "                \"axis-0\": frames,  # Frame number\n",
    "                \"axis-1\": points[:, 0],  # X-coordinates -> first column of array\n",
    "                \"axis-2\": points[:, 1],  # Y-coordinates -> second column of array\n",
    "            }\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "#\n",
    "def update_point_visibility(layer, viewer):\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        return\n",
    "\n",
    "    # Gets the current frame from the video, starting from where the viewer is\n",
    "    current_frame = viewer.dims.current_step[0]\n",
    "    # Gets the metadata associated with frames\n",
    "    frames = layer.metadata[\"frames\"]\n",
    "\n",
    "    # Update visibility based on current -> so visibility is true for the frames\n",
    "    # before and at the frame the viewer is on\n",
    "    visible = frames <= current_frame\n",
    "    layer.metadata[\"visible\"] = visible\n",
    "\n",
    "    # Update the displayed points -> points that are displayed are the ones\n",
    "    # that are listed as visible\n",
    "    if len(layer.data) > 0:\n",
    "        layer.shown = visible\n",
    "\n",
    "\n",
    "def store_frame_metadata(layer, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "    num_points = len(layer.data)  # Total points in the layer\n",
    "\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        layer.metadata[\"frames\"] = np.zeros(num_points, dtype=int)  # Initialize\n",
    "        layer.metadata[\"visible\"] = np.ones(\n",
    "            num_points, dtype=bool\n",
    "        )  # Initialize visibility\n",
    "\n",
    "    existing_frames = layer.metadata[\"frames\"]  # Get stored frame numbers\n",
    "\n",
    "    # If new points were added, store their frame numbers\n",
    "    if num_points > len(existing_frames):\n",
    "        new_frames = np.full(\n",
    "            num_points - len(existing_frames), current_frame\n",
    "        )  # Assign current frame to new points\n",
    "        layer.metadata[\"frames\"] = np.concatenate(\n",
    "            [existing_frames, new_frames]\n",
    "        )  # Update frames\n",
    "        # New points should be visible if current frame >= their frame\n",
    "        new_visible = np.ones(num_points - len(existing_frames), dtype=bool)\n",
    "        layer.metadata[\"visible\"] = np.concatenate(\n",
    "            [layer.metadata[\"visible\"], new_visible]\n",
    "        )\n",
    "\n",
    "    # Update visibility for all points\n",
    "    update_point_visibility(layer, viewer)\n",
    "\n",
    "\n",
    "# Goes through each layer and modifies data based on certain events, saving the\n",
    "# data to the layer when press 'S' key\n",
    "def annotate_video(video_path):\n",
    "    vr = VideoReaderNP(video_path)\n",
    "    viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "    # Add point layers\n",
    "    rewards_layer = viewer.add_points(name=\"rewards\", face_color=\"red\", size=10)\n",
    "    start_layer = viewer.add_points(name=\"start\", face_color=\"green\", size=10)\n",
    "    trials_layer = viewer.add_points(name=\"trials\", face_color=\"blue\", size=10)\n",
    "\n",
    "    point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "    # Attach event listeners -> so whenever the data changes (i.e., points\n",
    "    # are removed, added, or modified) or the viewer changes a frame,\n",
    "    # updates metadata and changes visuals (i.e., visible points), respectively\n",
    "    for layer in point_layers:\n",
    "        # Update frame metadata when points are added\n",
    "        layer.events.data.connect(\n",
    "            lambda event, l=layer: store_frame_metadata(l, viewer)\n",
    "        )\n",
    "\n",
    "        # Update visibility when frame changes\n",
    "        viewer.dims.events.current_step.connect(\n",
    "            lambda event: update_point_visibility(layer, viewer)\n",
    "        )\n",
    "\n",
    "    # Bind save function to 'S' key\n",
    "    @viewer.bind_key(\"Shift-S\")\n",
    "    def save_on_keypress(viewer):\n",
    "        save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "# Checks trial durations, number of trials, number of rewards, and each trial\n",
    "# has only 1 start time\n",
    "def verify_manual_annotation(video_path, fs=40, trial_wiggle_room=10):\n",
    "    if not is_annotated(video_path):\n",
    "        print(f\"{video_path} --- not annotated\")\n",
    "        return\n",
    "\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    trials = pd.read_csv(os.path.join(video_dir, \"trials.csv\"))\n",
    "    rewards = pd.read_csv(os.path.join(video_dir, \"rewards.csv\"))\n",
    "    start = pd.read_csv(os.path.join(video_dir, \"start.csv\"))\n",
    "\n",
    "    # check if any trial durations\n",
    "    trials = trials.sort_values(\"axis-0\").reset_index(drop=True)\n",
    "    # fills the even indexes of trials with start times\n",
    "    start_ind = trials[trials.index % 2 == 0][\"axis-0\"]\n",
    "    # fills the odd indexes of trials with end times\n",
    "    stop_ind = trials[trials.index % 2 == 1][\"axis-0\"]\n",
    "    # converts the indices into seconds by dividing by sampling frequency\n",
    "    starts = start_ind / fs\n",
    "    stops = stop_ind / fs\n",
    "    # check if same number of starts and stops -> sanity check ig?\n",
    "    assert len(starts) == len(stops), (\n",
    "        f\"Found {len(starts)} starts and {len(stops)} stops\"\n",
    "    )\n",
    "    # get durations per trial\n",
    "    durations = stops.values - starts.values\n",
    "\n",
    "    # check if any trial is longer than 360 seconds\n",
    "    assert durations.max() < 60 * 6, f\"Found {durations.max()} seconds\"\n",
    "    if durations.max() > 90:\n",
    "        print(f\"{video_path} --- Found {durations.max()} seconds\")\n",
    "\n",
    "    # check if any trial is shorter than 90 seconds\n",
    "    if durations.min() < 90:\n",
    "        test = 1\n",
    "    assert durations.min() > 5, f\"Found {durations.min()} seconds\"\n",
    "\n",
    "    # check if more than 25 trials\n",
    "    assert durations.shape[0] <= 30, f\"Found {durations.shape[0]} trials\"\n",
    "\n",
    "    # check if at least 2 rewards\n",
    "    assert rewards.shape[0] >= 2, f\"Found {rewards.shape[0]} rewards\"\n",
    "\n",
    "    # check if 1 start\n",
    "    assert start.shape[0] == 1, f\"Found {start.shape[0]} start points\"\n",
    "\n",
    "    print(f\"{video_path} --- verified\")\n",
    "\n",
    "\n",
    "def is_annotated(video_path):\n",
    "    video_dir = Path(video_path).parent\n",
    "    print(\"hey\")\n",
    "    if os.path.exists(os.path.join(video_dir, \"rewards.csv\")) & os.path.exists(os.path.join(video_dir, \"start.csv\")) & os.path.exists(os.path.join(video_dir, \"trials.csv\")):\n",
    "        print(\"treldkjf\")\n",
    "    else:\n",
    "        print(\"suckjerja;ldkjf;alskjdfa;lsdkjf\")\n",
    "    return (\n",
    "        os.path.exists(os.path.join(video_dir, \"rewards.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"start.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"trials.csv\"))\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"discovering files...\")\n",
    "\n",
    "    # files = glob.glob(r\"U:\\data\\hpc_ctx_project\\**\\*.avi\", recursive=True)\n",
    "\n",
    "    # files_series = pd.Series(files)\n",
    "    # idx = (\n",
    "    #     files_series.str.contains(\"cheeseboard|cheesboard|open_field|acquisition|probe\")\n",
    "    #     & ~files_series.str.contains(\"backup\")\n",
    "    #     & ~files_series.str.contains(\"test\")\n",
    "    # )\n",
    "\n",
    "    # files = list(compress(files, idx))\n",
    "    basepaths = pd.read_csv(r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\sample_data.csv\").basepath.unique()\n",
    "    files = []\n",
    "\n",
    "    for folder in basepaths:\n",
    "        print('hei')\n",
    "        files.extend(glob.glob(os.path.join(folder, \"**\", \"*.avi\"), recursive=True))\n",
    "\n",
    "    print(f\"Initial file count: {len(files)}\")\n",
    "    print(files)\n",
    "\n",
    "    print(\"filter to just probe sessions to start\")\n",
    "    files_series = pd.Series(files)\n",
    "    idx = ~files_series.str.contains(\"backup\") & ~files_series.str.contains(\"test\")\n",
    "    files = list(compress(files, idx))\n",
    "    print(files)\n",
    "    for video_path_i, video_path in enumerate(files):\n",
    "        print(f\"{video_path} --- {video_path_i} of {len(files)} files\")\n",
    "\n",
    "        video_dir = Path(video_path).parent\n",
    "\n",
    "        if is_annotated(video_path):\n",
    "            verify_manual_annotation(video_path)\n",
    "            continue\n",
    "\n",
    "        annotate_video(video_path)\n",
    "        verify_manual_annotation(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovering files...\n",
      "Initial file count: 8\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R_task_day07-07282025162805-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day07-07292025162301-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day06-07282025120514-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4446_hab_day03-08072025102037-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4447_hab_day02-08062025103921-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4489_hab_day03-08072025104730-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4441_hab_day01-08052025115729-0000.avi']\n",
      "filter to just probe sessions to start\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R_task_day07-07282025162805-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day07-07292025162301-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day06-07282025120514-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4446_hab_day03-08072025102037-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4447_hab_day02-08062025103921-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4489_hab_day03-08072025104730-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4441_hab_day01-08052025115729-0000.avi']\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4509_task_day07-07282025154250-0000.avi --- 0 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4509_task_day07-07282025154250-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi --- 1 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day07-07292025162301-0000.avi --- 2 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day07-07292025162301-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day06-07282025120514-0000.avi --- 3 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day06-07282025120514-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4446_hab_day03-08072025102037-0000.avi --- 4 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4446_hab_day03-08072025102037-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4447_hab_day02-08062025103921-0000.avi --- 5 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4447_hab_day02-08062025103921-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4489_hab_day03-08072025104730-0000.avi --- 6 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4489_hab_day03-08072025104730-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4441_hab_day01-08052025115729-0000.avi --- 7 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4441_hab_day01-08052025115729-0000.avi --- not annotated\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "\n",
    "# Goes through all the layers of the video, extracting the coordinates,\n",
    "# frames, and the visible data and creates a DataFrame with the according\n",
    "# coordinates for each frame.\n",
    "#\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    #A layer is a level at which an aspect of the video can be manipulated (i.e.,\n",
    "    #can contain videos, audio, images, text, or effects). Layers are used to\n",
    "    #superimpose on video clip over another or to add special efects.\n",
    "    for layer in point_layers:\n",
    "        # Extract point coordinates (N, 2)\n",
    "        points = layer.data\n",
    "        # Loads the frame data and, if not found, replaces with 0s\n",
    "        frames = layer.metadata.get(\"frames\", np.zeros(len(points), dtype=int))\n",
    "        # Loads the visible data and, if not found, replaces with 1s (always True)\n",
    "        visible = layer.metadata.get(\"visible\", np.ones(len(points), dtype=bool))\n",
    "\n",
    "        if len(points) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "\n",
    "        # Create DataFrame with required columns\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"index\": np.arange(len(points)),  # Index of each point\n",
    "                \"axis-0\": frames,  # Frame number\n",
    "                \"axis-1\": points[:, 0],  # X-coordinates -> first column of array\n",
    "                \"axis-2\": points[:, 1],  # Y-coordinates -> second column of array\n",
    "            }\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "#\n",
    "def update_point_visibility(layer, viewer):\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        return\n",
    "\n",
    "    # Gets the current frame from the video, starting from where the viewer is\n",
    "    current_frame = viewer.dims.current_step[0]\n",
    "    # Gets the metadata associated with frames\n",
    "    frames = layer.metadata[\"frames\"]\n",
    "\n",
    "    # Update visibility based on current -> so visibility is true for the frames\n",
    "    # before and at the frame the viewer is on\n",
    "    visible = frames <= current_frame\n",
    "    layer.metadata[\"visible\"] = visible\n",
    "\n",
    "    # Update the displayed points -> points that are displayed are the ones\n",
    "    # that are listed as visible\n",
    "    if len(layer.data) > 0:\n",
    "        layer.shown = visible\n",
    "\n",
    "\n",
    "def store_frame_metadata(layer, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "    num_points = len(layer.data)  # Total points in the layer\n",
    "\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        layer.metadata[\"frames\"] = np.zeros(num_points, dtype=int)  # Initialize\n",
    "        layer.metadata[\"visible\"] = np.ones(\n",
    "            num_points, dtype=bool\n",
    "        )  # Initialize visibility\n",
    "\n",
    "    existing_frames = layer.metadata[\"frames\"]  # Get stored frame numbers\n",
    "\n",
    "    # If new points were added, store their frame numbers\n",
    "    if num_points > len(existing_frames):\n",
    "        new_frames = np.full(\n",
    "            num_points - len(existing_frames), current_frame\n",
    "        )  # Assign current frame to new points\n",
    "        layer.metadata[\"frames\"] = np.concatenate(\n",
    "            [existing_frames, new_frames]\n",
    "        )  # Update frames\n",
    "        # New points should be visible if current frame >= their frame\n",
    "        new_visible = np.ones(num_points - len(existing_frames), dtype=bool)\n",
    "        layer.metadata[\"visible\"] = np.concatenate(\n",
    "            [layer.metadata[\"visible\"], new_visible]\n",
    "        )\n",
    "\n",
    "    # Update visibility for all points\n",
    "    update_point_visibility(layer, viewer)\n",
    "\n",
    "\n",
    "# Goes through each layer and modifies data based on certain events, saving the\n",
    "# data to the layer when press 'S' key\n",
    "def annotate_video(video_path):\n",
    "    vr = VideoReaderNP(video_path)\n",
    "    viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "    # Add point layers\n",
    "    rewards_layer = viewer.add_points(name=\"rewards\", face_color=\"red\", size=10)\n",
    "    start_layer = viewer.add_points(name=\"start\", face_color=\"green\", size=10)\n",
    "    trials_layer = viewer.add_points(name=\"trials\", face_color=\"blue\", size=10)\n",
    "\n",
    "    point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "    # Attach event listeners -> so whenever the data changes (i.e., points\n",
    "    # are removed, added, or modified) or the viewer changes a frame,\n",
    "    # updates metadata and changes visuals (i.e., visible points), respectively\n",
    "    for layer in point_layers:\n",
    "        # Update frame metadata when points are added\n",
    "        layer.events.data.connect(\n",
    "            lambda event, l=layer: store_frame_metadata(l, viewer)\n",
    "        )\n",
    "\n",
    "        # Update visibility when frame changes\n",
    "        viewer.dims.events.current_step.connect(\n",
    "            lambda event: update_point_visibility(layer, viewer)\n",
    "        )\n",
    "\n",
    "    # Bind save function to 'S' key\n",
    "    @viewer.bind_key(\"Shift-S\")\n",
    "    def save_on_keypress(viewer):\n",
    "        save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "# Checks trial durations, number of trials, number of rewards, and each trial\n",
    "# has only 1 start time\n",
    "def verify_manual_annotation(video_path, fs=40, trial_wiggle_room=10):\n",
    "    if not is_annotated(video_path):\n",
    "        print(f\"{video_path} --- not annotated\")\n",
    "        return\n",
    "\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    trials = pd.read_csv(os.path.join(video_dir, \"trials.csv\"))\n",
    "    rewards = pd.read_csv(os.path.join(video_dir, \"rewards.csv\"))\n",
    "    start = pd.read_csv(os.path.join(video_dir, \"start.csv\"))\n",
    "\n",
    "    # check if any trial durations\n",
    "    trials = trials.sort_values(\"axis-0\").reset_index(drop=True)\n",
    "    # fills the even indexes of trials with start times\n",
    "    start_ind = trials[trials.index % 2 == 0][\"axis-0\"]\n",
    "    # fills the odd indexes of trials with end times\n",
    "    stop_ind = trials[trials.index % 2 == 1][\"axis-0\"]\n",
    "    # converts the indices into seconds by dividing by sampling frequency\n",
    "    starts = start_ind / fs\n",
    "    stops = stop_ind / fs\n",
    "    # check if same number of starts and stops -> sanity check ig?\n",
    "    assert len(starts) == len(stops), (\n",
    "        f\"Found {len(starts)} starts and {len(stops)} stops\"\n",
    "    )\n",
    "    # get durations per trial\n",
    "    durations = stops.values - starts.values\n",
    "\n",
    "    # check if any trial is longer than 360 seconds\n",
    "    assert durations.max() < 60 * 6, f\"Found {durations.max()} seconds\"\n",
    "    if durations.max() > 90:\n",
    "        print(f\"{video_path} --- Found {durations.max()} seconds\")\n",
    "\n",
    "    # check if any trial is shorter than 90 seconds\n",
    "    if durations.min() < 90:\n",
    "        test = 1\n",
    "    assert durations.min() > 5, f\"Found {durations.min()} seconds\"\n",
    "\n",
    "    # check if more than 25 trials\n",
    "    assert durations.shape[0] <= 30, f\"Found {durations.shape[0]} trials\"\n",
    "\n",
    "    # check if at least 2 rewards\n",
    "    assert rewards.shape[0] >= 2, f\"Found {rewards.shape[0]} rewards\"\n",
    "\n",
    "    # check if 1 start\n",
    "    assert start.shape[0] == 1, f\"Found {start.shape[0]} start points\"\n",
    "\n",
    "    print(f\"{video_path} --- verified\")\n",
    "\n",
    "\n",
    "def is_annotated(video_path):\n",
    "    video_dir = Path(video_path).parent\n",
    "    print(\"hey\")\n",
    "    if os.path.exists(os.path.join(video_dir, \"rewards.csv\")) & os.path.exists(os.path.join(video_dir, \"start.csv\")) & os.path.exists(os.path.join(video_dir, \"trials.csv\")):\n",
    "        print(\"treldkjf\")\n",
    "    else:\n",
    "        print(\"suckjerja;ldkjf;alskjdfa;lsdkjf\")\n",
    "    return (\n",
    "        os.path.exists(os.path.join(video_dir, \"rewards.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"start.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"trials.csv\"))\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"discovering files...\")\n",
    "\n",
    "    # files = glob.glob(r\"U:\\data\\hpc_ctx_project\\**\\*.avi\", recursive=True)\n",
    "\n",
    "    # files_series = pd.Series(files)\n",
    "    # idx = (\n",
    "    #     files_series.str.contains(\"cheeseboard|cheesboard|open_field|acquisition|probe\")\n",
    "    #     & ~files_series.str.contains(\"backup\")\n",
    "    #     & ~files_series.str.contains(\"test\")\n",
    "    # )\n",
    "\n",
    "    # files = list(compress(files, idx))\n",
    "    # basepaths = pd.read_csv(\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\sample_data.csv\").basepath.unique()\n",
    "\n",
    "    # files = []\n",
    "\n",
    "    # for folder in basepaths:\n",
    "    #     print('hei')\n",
    "    #     files.extend(glob.glob(os.path.join(folder, \"**\", \"*.avi\"), recursive=True))\n",
    "\n",
    "    files = glob.glob(r'Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\*.avi')\n",
    "\n",
    "    print(f\"Initial file count: {len(files)}\")\n",
    "    print(files)\n",
    "\n",
    "    print(\"filter to just probe sessions to start\")\n",
    "    files_series = pd.Series(files)\n",
    "    idx = ~files_series.str.contains(\"backup\") & ~files_series.str.contains(\"test\")\n",
    "    files = list(compress(files, idx))\n",
    "    print(files)\n",
    "    for video_path_i, video_path in enumerate(files):\n",
    "        print(f\"{video_path} --- {video_path_i} of {len(files)} files\")\n",
    "\n",
    "        video_dir = Path(video_path).parent\n",
    "\n",
    "        if is_annotated(video_path):\n",
    "            verify_manual_annotation(video_path)\n",
    "            continue\n",
    "\n",
    "        annotate_video(video_path)\n",
    "        verify_manual_annotation(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(r'Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\*.avi')\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a new napari viewer\n",
    "# viewer = napari.Viewer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "path=r\"Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi\"\n",
    "vr = VideoReaderNP(path)\n",
    "# with napari.gui_qt():\n",
    "viewer = napari.view_image(vr, name=path)\n",
    "# Define initial points for each layer (you can modify these as needed)\n",
    "rewards_points = np.array([])  # Example points for rewards\n",
    "start_points = np.array([])    # Example points for start\n",
    "trials_points = np.array([])  # Example points for trials\n",
    "\n",
    "# Add point layers to the viewer\n",
    "rewards_layer = viewer.add_points(rewards_points, name='rewards', face_color='red', size=10, properties={'frame':[]})\n",
    "start_layer = viewer.add_points(start_points, name='start', face_color='green', size=10, properties={'frame':[]})\n",
    "trials_layer = viewer.add_points(trials_points, name='trials', face_color='blue', size=10, properties={'frame':[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "    # current_frame = viewer.dims.current_step[0]\n",
    "    for layer in point_layers:\n",
    "        save_path = video_dir / f\"{layer.name}_test.csv\"\n",
    "        layer.save(save_path)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "\n",
    "# Function to add frame number when a point is added\n",
    "def add_frame_to_point(layer, event):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get the current frame number\n",
    "    if \"frame\" not in layer.properties:\n",
    "        layer.properties[\"frame\"] = np.array([])\n",
    "    layer.properties[\"frame\"] = np.append(layer.properties[\"frame\"], current_frame)\n",
    "    \n",
    "# Path to your video file\n",
    "# video_path = \"path/to/your/video.mp4\"\n",
    "video_path=r\"Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi\"\n",
    "\n",
    "vr = VideoReaderNP(video_path)\n",
    "# with napari.gui_qt():\n",
    "viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "# Add initial point layers (optional)\n",
    "rewards_layer = viewer.add_points(name='rewards', face_color='red', size=10)\n",
    "start_layer = viewer.add_points(name='start', face_color='green', size=10)\n",
    "trials_layer = viewer.add_points(name='trials', face_color='blue', size=10)\n",
    "\n",
    "point_layers = [rewards_layer,start_layer,trials_layer]\n",
    "\n",
    "# Connect the save function to the viewer's close event\n",
    "@viewer.bind_key('S')  # Bind to a keypress (e.g., 'S' for save)\n",
    "def save_on_keypress(viewer):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "# Run the napari GUI\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmitterGroup' object has no attribute 'closed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 65\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;129m@viewer\u001b[39m\u001b[38;5;241m.\u001b[39mbind_key(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_on_keypress\u001b[39m(viewer):\n\u001b[0;32m     63\u001b[0m     save_layers_to_video_directory(viewer, video_path, point_layers)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;129m@viewer\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[38;5;241m.\u001b[39mconnect\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_on_close\u001b[39m(event):\n\u001b[0;32m     67\u001b[0m     save_layers_to_video_directory(viewer, video_path, point_layers)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto-saved on viewer close\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\schafferlab\\anaconda3\\envs\\new-napari-env\\lib\\site-packages\\napari\\utils\\events\\event.py:978\u001b[0m, in \u001b[0;36mEmitterGroup.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EventEmitter:\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EmitterGroup' object has no attribute 'closed'"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    for layer in point_layers:\n",
    "        points = layer.data  # Extract point coordinates (N, 2)\n",
    "        frames = layer.properties.get(\"frame\", np.array([]))  # Extract stored frame indices\n",
    "        \n",
    "        if len(points) == 0 or len(frames) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        frames = np.asarray(frames).reshape(-1, 1)  # Ensure frames are a column\n",
    "        points = np.asarray(points)  # Ensure points are NumPy array\n",
    "\n",
    "        # Combine index, frame, x, y into a DataFrame\n",
    "        df = pd.DataFrame(\n",
    "            np.column_stack([np.arange(len(points)), frames, points]),\n",
    "            columns=[\"index\", \"axis-0\", \"axis-1\", \"axis-2\"]\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}_annotations.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "# Function to add frame number when a point is added\n",
    "def add_frame_to_point(layer, event, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "\n",
    "    if \"frame\" not in layer.properties:\n",
    "        layer.properties[\"frame\"] = np.array([])  # Initialize frame property\n",
    "\n",
    "    layer.properties[\"frame\"] = np.append(layer.properties[\"frame\"], current_frame)\n",
    "\n",
    "# Path to your video file\n",
    "video_path = \"Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi\"\n",
    "\n",
    "vr = VideoReaderNP(video_path)\n",
    "viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "# Add point layers for annotations\n",
    "rewards_layer = viewer.add_points(name='rewards', face_color='red', size=10)\n",
    "start_layer = viewer.add_points(name='start', face_color='green', size=10)\n",
    "trials_layer = viewer.add_points(name='trials', face_color='blue', size=10)\n",
    "\n",
    "point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "# Attach event listener to each layer using partial to avoid lambda issues\n",
    "for layer in point_layers:\n",
    "    layer.events.data.connect(partial(add_frame_to_point, layer, viewer=viewer))\n",
    "\n",
    "# Bind save function to 'S' key\n",
    "@viewer.bind_key('S')\n",
    "def save_on_keypress(viewer):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "@viewer.events.closed.connect\n",
    "def save_on_close(event):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "    print(\"Auto-saved on viewer close\")\n",
    "\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
